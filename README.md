# DonaldsonDLC
Using markerless pose estimation to quantify mating bouts. The project uses a convolutional neural network to analyze mating videos and return a csv formatted file of poses. This file is then processed using a python script and garphed to show the covariation of movement between two voles. When complete, this project will save the lab hours of time which previously would have been used to hand mark each video. 

![](DLC_Mating_Vod.gif)


## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

### Prerequisites
Run in a windows 10 environment using Anaconda 4.7.5 and python 3.7.3

- Deep Lab Cut
  - [Download Instructions](http://www.mousemotorlab.org/deeplabcut)

- Python 3
  - [Download](https://www.python.org/downloads/)

- Anaconda
  - [Download](https://www.anaconda.com/distribution/)

### Installing

```Hello World!```
 

## Deployment

Additional notes about how to deploy this on a live system
```
Python 3.7.3
conda 4.7.5
```

## Built With

* [Anaconda](https://www.anaconda.com/) - Platform
* [Visual Studio Code](https://visualstudio.microsoft.com/) - IDE
* [Python 3](https://www.python.org/) - Code Language 
* [DeepLabCut](http://www.mousemotorlab.org/deeplabcut) - Markerless pose estimator


## Versioning

I use vole related versioning. For the versions available, see the [tags on this repository](https://github.com/donaldsonlab/UI-lab-capture/tags). **No Current Versions Available**

## Authors

* **Chase Dudas** - *ML/Scripts/Analysis* - [Personal GitHub](https://github.com/ChaseD13)

## License

This project is not licensed

## Acknowledgments

* Nath, Mathis et al, 2019
* David Protter w/ Donaldson Lab
